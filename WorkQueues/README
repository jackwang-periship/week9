The main idea behind Work Queues (aka: Task Queues) is to avoid doing a resource-intensive task immediately
and having to wait for it to complete. Instead we schedule the task to be done later. 
We encapsulate a task as a message and send it to the queue. 
A worker process running in the background will pop the tasks and eventually execute the job. 
When you run many workers the tasks will be shared between them.


					
                     /-----> WORKER_1
  P --->| | | | | | /
                    \
                     \-----> WORKER_2
                     
                     
  
* Fair dispatch
You might have noticed that the dispatching still doesn't work exactly as we want. 
For example in a situation with two workers, when all odd messages are heavy and even messages are light, 
one worker will be constantly busy and the other one will do hardly any work. Well, 
RabbitMQ doesn't know anything about that and will still dispatch messages evenly.
This happens because RabbitMQ just dispatches a message when the message enters the queue. 
It doesn't look at the number of unacknowledged messages for a consumer. 
It just blindly dispatches every n-th message to the n-th consumer.


* Message durability

We have learned how to make sure that even if the consumer dies, 
the task isn't lost. But our tasks will still be lost if RabbitMQ server stops.
When RabbitMQ quits or crashes it will forget the queues and messages unless you tell it not to. 
Two things are required to make sure that messages aren't lost: we need to mark both the queue and messages as durable.

First, we need to make sure that RabbitMQ will never lose our queue. In order to do so, 
we need to declare it as durable:

	channel.queue_declare(queue='hello', durable=True)

Although this command is correct by itself, it won't work in our setup. 
That's because we've already defined a queue called hello which is not durable. 
RabbitMQ doesn't allow you to redefine an existing queue with different parameters and 
will return an error to any program that tries to do that. 
But there is a quick workaround - let's declare a queue with different name, for example task_queue:

 	channel.queue_declare(queue='task_queue', durable=True)
 
 This queue_declare change needs to be applied to both the producer and consumer code.

At that point we're sure that the task_queue queue won't be lost even if RabbitMQ restarts. 
Now we need to mark our messages as persistent - by supplying a delivery_mode property with a value 2.



*Message acknowledgment

Doing a task can take a few seconds. You may wonder what happens if one of the consumers starts a long task and dies with it only partly done. 
With our current code once RabbitMQ delivers message to the customer it immediately removes it from memory. 
In this case, if you kill a worker we will lose the message it was just processing. 
We'll also lose all the messages that were dispatched to this particular worker but were not yet handled.

But we don't want to lose any tasks. If a worker dies, we'd like the task to be delivered to another worker.

In order to make sure a message is never lost, RabbitMQ supports message acknowledgments. 
An ack(nowledgement) is sent back from the consumer to tell RabbitMQ that a particular message had been received, 
processed and that RabbitMQ is free to delete it.

If a consumer dies (its channel is closed, connection is closed, or TCP connection is lost) without sending an ack, 
RabbitMQ will understand that a message wasn't processed fully and will re-queue it. If there are other consumers online at the same time, 
it will then quickly redeliver it to another consumer. That way you can be sure that no message is lost, even if the workers occasionally die.

There aren't any message timeouts; RabbitMQ will redeliver the message when the consumer dies. 
It's fine even if processing a message takes a very, very long time.

Message acknowledgments are turned on by default. In previous examples we explicitly turned them off via the no_ack=True flag. 
It's time to remove this flag and send a proper acknowledgment from the worker, once we're done with a task.

	def callback(ch, method, properties, body):
	    print " [x] Received %r" % (body,)
	    time.sleep( body.count('.') )
	    print " [x] Done"
	    ch.basic_ack(delivery_tag = method.delivery_tag)
	
	channel.basic_consume(callback,
	                      queue='hello')

Using this code we can be sure that even if you kill a worker using CTRL+C while it was processing a message, 
nothing will be lost. Soon after the worker dies all unacknowledged messages will be redelivered.


* Forgotten acknowledgment

It's a common mistake to miss the basic_ack. It's an easy error, but the consequences are serious. 
Messages will be redelivered when your client quits (which may look like random redelivery), 
but RabbitMQ will eat more and more memory as it won't be able to release any unacked messages.

In order to debug this kind of mistake you can use rabbitmqctl to print the messages_unacknowledged field:

	sudo rabbitmqctl list_queues name messages_ready messages_unacknowledged

